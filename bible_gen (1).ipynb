{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bible_gen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQDCd8nDkGDm",
        "outputId": "0f157390-e3ae-4c00-c4c6-fe70c12070f2"
      },
      "source": [
        "!pip install gpt-2-simple\n",
        "\n",
        "# the transformers package is built on top of Tensorflow, and the default TF version \n",
        "# for Colab will soon switch to 2.x. We remedy this with the following magic method\n",
        "%tensorflow_version 1.x \n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt-2-simple\n",
            "  Downloading gpt_2_simple-0.7.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (1.19.5)\n",
            "Collecting toposort\n",
            "  Downloading toposort-1.6-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.2-py3-none-any.whl size=23620 sha256=48919eecdec2c276f42757c4b499006823fe70616dfd466052460075db861bcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/a0/0b/18b541426b0d966b55ae6dc35628a85f67d0698e5fabb1d6c7\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.2 toposort-1.6\n",
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EAtYfDmlo4H",
        "outputId": "b112fac6-daee-4ddc-c087-383c77b17a62"
      },
      "source": [
        "# download the data\n",
        "!wget https://raw.githubusercontent.com/elizabethg123/files/main/new_testament.rtf\n",
        "\n",
        "# read the data\n",
        "f = open(\"/content/new_testament.rtf\", \"r\")\n",
        "bible = f.read()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-29 00:40:53--  https://raw.githubusercontent.com/elizabethg123/files/main/new_testament.rtf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 957816 (935K) [text/plain]\n",
            "Saving to: ‘new_testament.rtf’\n",
            "\n",
            "new_testament.rtf   100%[===================>] 935.37K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-07-29 00:40:53 (131 MB/s) - ‘new_testament.rtf’ saved [957816/957816]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeMS8LFRl_fq",
        "outputId": "0d2a88ff-53f5-43a9-eb15-4bded477f690"
      },
      "source": [
        "# This line is necessary to be able to run a new tf session\n",
        "tf.reset_default_graph()\n",
        "model_name = \"124M\"\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "\tprint(f\"Downloading {model_name} model...\")\n",
        "\tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, model_name=model_name)\n",
        "gpt2.generate(sess, model_name=model_name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 124M model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 527Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 5.77Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 213Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:08, 56.0Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 201Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 9.14Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 7.16Mit/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "(Reuters) -\n",
            "\n",
            "More than 1,000 members of a California civil rights group have submitted a lawsuit against California Department of Justice (DOJ) officials for failing to prosecute alleged sex crimes against deputies in the department's Violent Crimes Unit.\n",
            "\n",
            "The group, called Operation North Star, sued the state's Attorney General's office over the department's handling of the case last month.\n",
            "\n",
            "Operation North Star alleged that the department mishandled the case after it was reported there were allegations of sexual assault against deputies, and that officers were underpaid.\n",
            "\n",
            "It was unsuccessful in filing a lawsuit in federal court, which could take up to 20 years.\n",
            "\n",
            "DOJ spokeswoman Wendy McElhinney said the office has not commented on the case.\n",
            "\n",
            "The state's civil rights division had earlier filed a lawsuit against the DOJ for failing to pursue the case despite numerous requests by the federal government.\n",
            "\n",
            "DOJ Chief Deputy Department Attorney Ryan Woods said in a statement on Tuesday that the department has \"resolved the alleged allegations of sexual assault against [Deputy Chief of Staff] Micah Johnson and his deputies.\"\n",
            "\n",
            "\"The allegations are false and the allegations are unfounded, and the department has thoroughly investigated them, and has made its evidence available to the public to assist in the review,\" Woods said.<|endoftext|>From darkspawn.com\n",
            "\n",
            "This article or section is incomplete. You can help by adding it\n",
            "\n",
            "This article or section is currently incomplete\n",
            "\n",
            "Please add a section to this article.\n",
            "\n",
            "This article or section is incomplete. You can help by adding it\n",
            "\n",
            "This article or section is incomplete\n",
            "\n",
            "This article or section is incomplete\n",
            "\n",
            "This article or section is incomplete\n",
            "\n",
            "This article or section is incomplete\n",
            "\n",
            "This article or section is incomplete\n",
            "\n",
            "This article or section is incomplete\n",
            "\n",
            "This article or section is incomplete\n",
            "\n",
            "This article or section is incomplete\n",
            "\n",
            "This article or section is incomplete\n",
            "\n",
            "This article or section is incomplete<|endoftext|>It's a strange one.\n",
            "\n",
            "For the past year, the United States is having a remarkably successful season. Just one year after the Republican National Convention, Republicans won 50 states and the District of Columbia and have won a combined 50 seats in the House of Representatives.\n",
            "\n",
            "But for all the talk about money in politics, the Republican Party is in some ways trying to get back to its roots.\n",
            "\n",
            "Not that the party is working as hard as in previous elections.\n",
            "\n",
            "The GOP is not trying to win every election.\n",
            "\n",
            "The party is trying to win every federal election in America.\n",
            "\n",
            "The party isn't trying to win every state in America because it's afraid of losing every one of them.\n",
            "\n",
            "The party is trying to win every state in America because \"the people of this country aren't going to grow up knowing that in this country we have the freedom to choose who we can be and what we want to be.\"\n",
            "\n",
            "The party is trying to win every state in America because it's afraid of losing every one of them.\n",
            "\n",
            "The party is trying to win every state in America because it's afraid of winning every single one of them.\n",
            "\n",
            "The party is trying to win every state in America because it's afraid of losing every one of them.\n",
            "\n",
            "It's the same with the GOP.\n",
            "\n",
            "It's the same with the GOP.\n",
            "\n",
            "Back in 2008, President George W. Bush and Republican Party leaders talked about rolling back the president's executive actions on immigration, and the Republican Party's supporters, including former New York City Mayor Rudy Giuliani, noted that \"the people of this country have no business being on the sidelines.\"\n",
            "\n",
            "As President Obama's party has followed through with his policies, it's not surprising that the Republicans are nervous about losing their new majority.\n",
            "\n",
            "But should the party be worried?\n",
            "\n",
            "Conservatives and their base trusted President Obama's new executive action to keep immigration from coming to the United States. The threat of deportation was so great that the GOP's base put a hold on it.\n",
            "\n",
            "The Republican Party thought it could win back the majority by doing everything it could to stop the immigration program. But as the future of the party is in danger, the GOP's direction is clear.\n",
            "\n",
            "Instead of focusing on victory and winning every single election, the GOP is trying to keep the party in the ground.\n",
            "\n",
            "The GOP is trying to get back to its roots.\n",
            "\n",
            "At the same time, it's attempting to win the hearts of the American people.\n",
            "\n",
            "The Republican Party is trying to win the hearts of Americans.\n",
            "\n",
            "The Republican Party is trying to win the hearts of America.\n",
            "\n",
            "And in the process, it's trying to get back to its roots.\n",
            "\n",
            "Here are five reasons why the Republican Party is trying to win every single election in America.\n",
            "\n",
            "1. The GOP Is Not Trying to Win Every Election\n",
            "\n",
            "A lot of people don't understand what the Republican Party is trying to win every election.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GmxkkE2GmNeB",
        "outputId": "c5646347-94b3-4df6-bd2f-59d62eb743e1"
      },
      "source": [
        "# reset graph\n",
        "tf.reset_default_graph()\n",
        "# Start a session\n",
        "sess = gpt2.start_tf_sess()\n",
        "# Fine tune `model_name` on bible\n",
        "gpt2.finetune(sess,\n",
        "              dataset=\"/content/new_testament.rtf\",\n",
        "              model_name=model_name,\n",
        "              restore_from='latest',\n",
        "              sample_length=100,\n",
        "              steps=1000)   # max number of training steps\n",
        "\n",
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-600\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 239613 tokens\n",
            "Training...\n",
            "======== SAMPLE 1 ========\n",
            " earth shall be made manifest, so that ye may rejoice and be filled;\\\n",
            "For which cause have I set down this saying, that all men may know it, and rejoice in it.\\\n",
            "Seeing therefore it is written, I will sing of you, Shewed thyself falling down from heaven, thou shalt see it again.\\\n",
            "But this the angels believest: for they heard that the Son of man is coming.\\\n",
            "Then said they, It is written in the prophets,\n",
            "\n",
            "[601 | 13.38] loss=0.40 avg=0.40\n",
            "[602 | 15.67] loss=0.70 avg=0.55\n",
            "[603 | 17.94] loss=0.33 avg=0.48\n",
            "[604 | 20.24] loss=0.66 avg=0.52\n",
            "[605 | 22.53] loss=0.35 avg=0.49\n",
            "[606 | 24.85] loss=0.39 avg=0.47\n",
            "[607 | 27.17] loss=0.29 avg=0.44\n",
            "[608 | 29.51] loss=0.39 avg=0.44\n",
            "[609 | 31.87] loss=0.35 avg=0.43\n",
            "[610 | 34.24] loss=0.64 avg=0.45\n",
            "[611 | 36.62] loss=0.28 avg=0.43\n",
            "[612 | 39.00] loss=0.40 avg=0.43\n",
            "[613 | 41.40] loss=0.49 avg=0.43\n",
            "[614 | 43.80] loss=0.50 avg=0.44\n",
            "[615 | 46.19] loss=0.52 avg=0.45\n",
            "[616 | 48.57] loss=0.33 avg=0.44\n",
            "[617 | 50.93] loss=0.92 avg=0.47\n",
            "[618 | 53.29] loss=0.35 avg=0.46\n",
            "[619 | 55.63] loss=0.39 avg=0.46\n",
            "[620 | 57.96] loss=0.42 avg=0.45\n",
            "[621 | 60.29] loss=0.35 avg=0.45\n",
            "[622 | 62.61] loss=0.41 avg=0.45\n",
            "[623 | 64.92] loss=0.42 avg=0.45\n",
            "[624 | 67.22] loss=0.29 avg=0.44\n",
            "[625 | 69.51] loss=0.33 avg=0.43\n",
            "[626 | 71.81] loss=0.34 avg=0.43\n",
            "[627 | 74.09] loss=0.36 avg=0.43\n",
            "[628 | 76.37] loss=0.23 avg=0.42\n",
            "[629 | 78.65] loss=0.38 avg=0.42\n",
            "[630 | 80.92] loss=0.29 avg=0.41\n",
            "[631 | 83.20] loss=0.51 avg=0.42\n",
            "[632 | 85.48] loss=0.33 avg=0.41\n",
            "[633 | 87.75] loss=0.37 avg=0.41\n",
            "[634 | 90.03] loss=0.36 avg=0.41\n",
            "[635 | 92.31] loss=0.41 avg=0.41\n",
            "[636 | 94.59] loss=0.37 avg=0.41\n",
            "[637 | 96.87] loss=0.36 avg=0.41\n",
            "[638 | 99.15] loss=0.23 avg=0.40\n",
            "[639 | 101.43] loss=0.42 avg=0.40\n",
            "[640 | 103.71] loss=0.33 avg=0.40\n",
            "[641 | 106.00] loss=0.36 avg=0.40\n",
            "[642 | 108.28] loss=0.52 avg=0.40\n",
            "[643 | 110.58] loss=0.53 avg=0.41\n",
            "[644 | 112.88] loss=0.31 avg=0.40\n",
            "[645 | 115.18] loss=0.40 avg=0.40\n",
            "[646 | 117.48] loss=0.24 avg=0.40\n",
            "[647 | 119.79] loss=0.32 avg=0.40\n",
            "[648 | 122.10] loss=0.40 avg=0.40\n",
            "[649 | 124.41] loss=0.36 avg=0.40\n",
            "[650 | 126.73] loss=0.26 avg=0.39\n",
            "[651 | 129.05] loss=0.38 avg=0.39\n",
            "[652 | 131.37] loss=0.29 avg=0.39\n",
            "[653 | 133.70] loss=0.20 avg=0.38\n",
            "[654 | 136.01] loss=0.34 avg=0.38\n",
            "[655 | 138.34] loss=0.47 avg=0.39\n",
            "[656 | 140.66] loss=0.35 avg=0.38\n",
            "[657 | 142.97] loss=0.38 avg=0.38\n",
            "[658 | 145.28] loss=0.25 avg=0.38\n",
            "[659 | 147.59] loss=0.23 avg=0.38\n",
            "[660 | 149.91] loss=0.30 avg=0.38\n",
            "[661 | 152.21] loss=0.40 avg=0.38\n",
            "[662 | 154.51] loss=0.27 avg=0.37\n",
            "[663 | 156.82] loss=0.31 avg=0.37\n",
            "[664 | 159.11] loss=0.28 avg=0.37\n",
            "[665 | 161.42] loss=0.33 avg=0.37\n",
            "[666 | 163.72] loss=0.30 avg=0.37\n",
            "[667 | 166.01] loss=0.20 avg=0.37\n",
            "[668 | 168.30] loss=0.26 avg=0.36\n",
            "[669 | 170.59] loss=0.37 avg=0.36\n",
            "[670 | 172.89] loss=0.18 avg=0.36\n",
            "[671 | 175.19] loss=0.63 avg=0.37\n",
            "[672 | 177.49] loss=0.27 avg=0.36\n",
            "[673 | 179.79] loss=0.42 avg=0.36\n",
            "[674 | 182.09] loss=0.20 avg=0.36\n",
            "[675 | 184.38] loss=0.23 avg=0.36\n",
            "[676 | 186.69] loss=0.33 avg=0.36\n",
            "[677 | 188.99] loss=0.20 avg=0.36\n",
            "[678 | 191.29] loss=0.28 avg=0.35\n",
            "[679 | 193.58] loss=0.20 avg=0.35\n",
            "[680 | 195.88] loss=0.27 avg=0.35\n",
            "[681 | 198.18] loss=0.27 avg=0.35\n",
            "[682 | 200.47] loss=0.27 avg=0.35\n",
            "[683 | 202.78] loss=0.28 avg=0.35\n",
            "[684 | 205.07] loss=0.20 avg=0.34\n",
            "[685 | 207.37] loss=0.21 avg=0.34\n",
            "[686 | 209.68] loss=0.29 avg=0.34\n",
            "[687 | 211.97] loss=0.32 avg=0.34\n",
            "[688 | 214.28] loss=0.42 avg=0.34\n",
            "[689 | 216.58] loss=0.34 avg=0.34\n",
            "[690 | 218.87] loss=0.18 avg=0.34\n",
            "[691 | 221.16] loss=0.30 avg=0.34\n",
            "[692 | 223.46] loss=0.18 avg=0.33\n",
            "[693 | 225.76] loss=0.24 avg=0.33\n",
            "[694 | 228.06] loss=0.28 avg=0.33\n",
            "[695 | 230.35] loss=0.37 avg=0.33\n",
            "[696 | 232.66] loss=0.27 avg=0.33\n",
            "[697 | 234.96] loss=0.24 avg=0.33\n",
            "[698 | 237.26] loss=0.28 avg=0.33\n",
            "[699 | 239.56] loss=0.29 avg=0.33\n",
            "[700 | 241.86] loss=0.24 avg=0.33\n",
            "======== SAMPLE 1 ========\n",
            " sin, and say, It is done in secret.\\\n",
            "The people gladly accept the thing, for the deed is performed in the secret, and in the temple, and in all the palace, and in the markets and in the synagogues; and they salute you joyfully.\\\n",
            "But ye, brethren, which are with me in the secret, and among the saints, be in Christ Jesus:\\\n",
            "When indeed ye are come and walk after his sufferings, be ye partial, even\n",
            "\n",
            "[701 | 245.11] loss=0.37 avg=0.33\n",
            "[702 | 247.41] loss=0.26 avg=0.33\n",
            "[703 | 249.71] loss=0.17 avg=0.32\n",
            "[704 | 252.01] loss=0.46 avg=0.33\n",
            "[705 | 254.31] loss=0.17 avg=0.32\n",
            "[706 | 256.61] loss=0.23 avg=0.32\n",
            "[707 | 258.91] loss=0.20 avg=0.32\n",
            "[708 | 261.20] loss=0.17 avg=0.32\n",
            "[709 | 263.50] loss=0.27 avg=0.32\n",
            "[710 | 265.80] loss=0.30 avg=0.32\n",
            "[711 | 268.10] loss=0.20 avg=0.32\n",
            "[712 | 270.41] loss=0.24 avg=0.32\n",
            "[713 | 272.71] loss=0.37 avg=0.32\n",
            "[714 | 275.01] loss=0.33 avg=0.32\n",
            "[715 | 277.31] loss=0.33 avg=0.32\n",
            "[716 | 279.61] loss=0.19 avg=0.31\n",
            "[717 | 281.91] loss=0.30 avg=0.31\n",
            "[718 | 284.21] loss=0.20 avg=0.31\n",
            "[719 | 286.52] loss=0.28 avg=0.31\n",
            "[720 | 288.81] loss=0.23 avg=0.31\n",
            "[721 | 291.11] loss=0.29 avg=0.31\n",
            "[722 | 293.41] loss=0.21 avg=0.31\n",
            "[723 | 295.71] loss=0.24 avg=0.31\n",
            "[724 | 298.02] loss=0.22 avg=0.31\n",
            "[725 | 300.32] loss=0.17 avg=0.30\n",
            "[726 | 302.62] loss=0.22 avg=0.30\n",
            "[727 | 304.92] loss=0.27 avg=0.30\n",
            "[728 | 307.22] loss=0.28 avg=0.30\n",
            "[729 | 309.52] loss=0.13 avg=0.30\n",
            "[730 | 311.82] loss=0.17 avg=0.30\n",
            "[731 | 314.12] loss=0.24 avg=0.30\n",
            "[732 | 316.43] loss=0.22 avg=0.30\n",
            "[733 | 318.72] loss=0.29 avg=0.30\n",
            "[734 | 321.03] loss=0.19 avg=0.30\n",
            "[735 | 323.34] loss=0.24 avg=0.29\n",
            "[736 | 325.64] loss=0.21 avg=0.29\n",
            "[737 | 327.94] loss=0.33 avg=0.29\n",
            "[738 | 330.24] loss=0.23 avg=0.29\n",
            "[739 | 332.55] loss=0.19 avg=0.29\n",
            "[740 | 334.85] loss=0.17 avg=0.29\n",
            "[741 | 337.17] loss=0.19 avg=0.29\n",
            "[742 | 339.47] loss=0.17 avg=0.29\n",
            "[743 | 341.77] loss=0.19 avg=0.29\n",
            "[744 | 344.08] loss=0.22 avg=0.28\n",
            "[745 | 346.39] loss=0.27 avg=0.28\n",
            "[746 | 348.68] loss=0.31 avg=0.29\n",
            "[747 | 350.99] loss=0.24 avg=0.28\n",
            "[748 | 353.29] loss=0.16 avg=0.28\n",
            "[749 | 355.59] loss=0.19 avg=0.28\n",
            "[750 | 357.90] loss=0.16 avg=0.28\n",
            "[751 | 360.20] loss=0.23 avg=0.28\n",
            "[752 | 362.51] loss=0.19 avg=0.28\n",
            "[753 | 364.81] loss=0.21 avg=0.28\n",
            "[754 | 367.10] loss=0.25 avg=0.28\n",
            "[755 | 369.41] loss=0.17 avg=0.28\n",
            "[756 | 371.71] loss=0.28 avg=0.28\n",
            "[757 | 374.01] loss=0.21 avg=0.28\n",
            "[758 | 376.33] loss=0.26 avg=0.27\n",
            "[759 | 378.63] loss=0.24 avg=0.27\n",
            "[760 | 380.94] loss=0.22 avg=0.27\n",
            "[761 | 383.25] loss=0.17 avg=0.27\n",
            "[762 | 385.55] loss=0.19 avg=0.27\n",
            "[763 | 387.86] loss=0.24 avg=0.27\n",
            "[764 | 390.15] loss=0.23 avg=0.27\n",
            "[765 | 392.46] loss=0.15 avg=0.27\n",
            "[766 | 394.76] loss=0.17 avg=0.27\n",
            "[767 | 397.07] loss=0.24 avg=0.27\n",
            "[768 | 399.38] loss=0.28 avg=0.27\n",
            "[769 | 401.67] loss=0.19 avg=0.27\n",
            "[770 | 403.97] loss=0.13 avg=0.27\n",
            "[771 | 406.27] loss=0.17 avg=0.26\n",
            "[772 | 408.58] loss=0.19 avg=0.26\n",
            "[773 | 410.88] loss=0.15 avg=0.26\n",
            "[774 | 413.18] loss=0.14 avg=0.26\n",
            "[775 | 415.48] loss=0.16 avg=0.26\n",
            "[776 | 417.79] loss=0.19 avg=0.26\n",
            "[777 | 420.09] loss=0.28 avg=0.26\n",
            "[778 | 422.39] loss=0.20 avg=0.26\n",
            "[779 | 424.69] loss=0.20 avg=0.26\n",
            "[780 | 427.00] loss=0.16 avg=0.26\n",
            "[781 | 429.30] loss=0.16 avg=0.25\n",
            "[782 | 431.60] loss=0.12 avg=0.25\n",
            "[783 | 433.90] loss=0.13 avg=0.25\n",
            "[784 | 436.20] loss=0.34 avg=0.25\n",
            "[785 | 438.50] loss=0.18 avg=0.25\n",
            "[786 | 440.80] loss=0.18 avg=0.25\n",
            "[787 | 443.09] loss=0.20 avg=0.25\n",
            "[788 | 445.39] loss=0.19 avg=0.25\n",
            "[789 | 447.69] loss=0.10 avg=0.25\n",
            "[790 | 449.99] loss=0.15 avg=0.25\n",
            "[791 | 452.28] loss=0.14 avg=0.25\n",
            "[792 | 454.58] loss=0.16 avg=0.24\n",
            "[793 | 456.88] loss=0.20 avg=0.24\n",
            "[794 | 459.19] loss=0.14 avg=0.24\n",
            "[795 | 461.49] loss=0.20 avg=0.24\n",
            "[796 | 463.79] loss=0.14 avg=0.24\n",
            "[797 | 466.09] loss=0.12 avg=0.24\n",
            "[798 | 468.38] loss=0.15 avg=0.24\n",
            "[799 | 470.67] loss=0.17 avg=0.24\n",
            "[800 | 472.98] loss=0.13 avg=0.24\n",
            "======== SAMPLE 1 ========\n",
            " I was moved with joy, that I should be made manifest in his name.\\\n",
            "And at the second sign the Lord opened unto me the earth, and the sea, and the fountains of waters.\\\n",
            "And he wept with a loud voice because of the earth and the fountains of waters,\\\n",
            "Foranism, andἰπιστίον.\\\n",
            "And I Beheld the great trees, and the fountains of waters,\n",
            "\n",
            "[801 | 476.20] loss=0.14 avg=0.24\n",
            "[802 | 478.51] loss=0.21 avg=0.24\n",
            "[803 | 480.81] loss=0.15 avg=0.23\n",
            "[804 | 483.11] loss=0.13 avg=0.23\n",
            "[805 | 485.42] loss=0.19 avg=0.23\n",
            "[806 | 487.72] loss=0.22 avg=0.23\n",
            "[807 | 490.03] loss=0.13 avg=0.23\n",
            "[808 | 492.32] loss=0.22 avg=0.23\n",
            "[809 | 494.62] loss=0.21 avg=0.23\n",
            "[810 | 496.92] loss=0.13 avg=0.23\n",
            "[811 | 499.22] loss=0.16 avg=0.23\n",
            "[812 | 501.52] loss=0.17 avg=0.23\n",
            "[813 | 503.82] loss=0.22 avg=0.23\n",
            "[814 | 506.11] loss=0.16 avg=0.23\n",
            "[815 | 508.41] loss=0.21 avg=0.23\n",
            "[816 | 510.71] loss=0.11 avg=0.23\n",
            "[817 | 513.01] loss=0.17 avg=0.23\n",
            "[818 | 515.32] loss=0.17 avg=0.22\n",
            "[819 | 517.61] loss=0.14 avg=0.22\n",
            "[820 | 519.91] loss=0.15 avg=0.22\n",
            "[821 | 522.22] loss=0.18 avg=0.22\n",
            "[822 | 524.51] loss=0.12 avg=0.22\n",
            "[823 | 526.81] loss=0.15 avg=0.22\n",
            "[824 | 529.12] loss=0.24 avg=0.22\n",
            "[825 | 531.42] loss=0.14 avg=0.22\n",
            "[826 | 533.73] loss=0.17 avg=0.22\n",
            "[827 | 536.03] loss=0.12 avg=0.22\n",
            "[828 | 538.33] loss=0.12 avg=0.22\n",
            "[829 | 540.63] loss=0.15 avg=0.22\n",
            "[830 | 542.92] loss=0.20 avg=0.22\n",
            "[831 | 545.23] loss=0.15 avg=0.22\n",
            "[832 | 547.53] loss=0.16 avg=0.21\n",
            "[833 | 549.84] loss=0.14 avg=0.21\n",
            "[834 | 552.13] loss=0.18 avg=0.21\n",
            "[835 | 554.43] loss=0.23 avg=0.21\n",
            "[836 | 556.74] loss=0.15 avg=0.21\n",
            "[837 | 559.03] loss=0.17 avg=0.21\n",
            "[838 | 561.33] loss=0.16 avg=0.21\n",
            "[839 | 563.62] loss=0.13 avg=0.21\n",
            "[840 | 565.92] loss=0.16 avg=0.21\n",
            "[841 | 568.21] loss=0.15 avg=0.21\n",
            "[842 | 570.51] loss=0.11 avg=0.21\n",
            "[843 | 572.82] loss=0.14 avg=0.21\n",
            "[844 | 575.11] loss=0.13 avg=0.21\n",
            "[845 | 577.42] loss=0.18 avg=0.21\n",
            "[846 | 579.71] loss=0.15 avg=0.21\n",
            "[847 | 582.03] loss=0.12 avg=0.21\n",
            "[848 | 584.33] loss=0.19 avg=0.20\n",
            "[849 | 586.63] loss=0.12 avg=0.20\n",
            "[850 | 588.93] loss=0.11 avg=0.20\n",
            "[851 | 591.23] loss=0.17 avg=0.20\n",
            "[852 | 593.54] loss=0.19 avg=0.20\n",
            "[853 | 595.83] loss=0.14 avg=0.20\n",
            "[854 | 598.13] loss=0.14 avg=0.20\n",
            "[855 | 600.43] loss=0.14 avg=0.20\n",
            "[856 | 602.73] loss=0.16 avg=0.20\n",
            "[857 | 605.03] loss=0.11 avg=0.20\n",
            "[858 | 607.34] loss=0.13 avg=0.20\n",
            "[859 | 609.64] loss=0.14 avg=0.20\n",
            "[860 | 611.94] loss=0.15 avg=0.20\n",
            "[861 | 614.24] loss=0.13 avg=0.20\n",
            "[862 | 616.54] loss=0.10 avg=0.20\n",
            "[863 | 618.85] loss=0.14 avg=0.19\n",
            "[864 | 621.16] loss=0.10 avg=0.19\n",
            "[865 | 623.46] loss=0.10 avg=0.19\n",
            "[866 | 625.77] loss=0.11 avg=0.19\n",
            "[867 | 628.07] loss=0.16 avg=0.19\n",
            "[868 | 630.36] loss=0.11 avg=0.19\n",
            "[869 | 632.66] loss=0.14 avg=0.19\n",
            "[870 | 634.96] loss=0.10 avg=0.19\n",
            "[871 | 637.27] loss=0.12 avg=0.19\n",
            "[872 | 639.57] loss=0.11 avg=0.19\n",
            "[873 | 641.87] loss=0.10 avg=0.19\n",
            "[874 | 644.16] loss=0.11 avg=0.19\n",
            "[875 | 646.47] loss=0.12 avg=0.19\n",
            "[876 | 648.77] loss=0.10 avg=0.18\n",
            "[877 | 651.08] loss=0.14 avg=0.18\n",
            "[878 | 653.38] loss=0.10 avg=0.18\n",
            "[879 | 655.68] loss=0.11 avg=0.18\n",
            "[880 | 657.98] loss=0.11 avg=0.18\n",
            "[881 | 660.28] loss=0.17 avg=0.18\n",
            "[882 | 662.59] loss=0.12 avg=0.18\n",
            "[883 | 664.89] loss=0.14 avg=0.18\n",
            "[884 | 667.20] loss=0.12 avg=0.18\n",
            "[885 | 669.50] loss=0.10 avg=0.18\n",
            "[886 | 671.80] loss=0.13 avg=0.18\n",
            "[887 | 674.11] loss=0.15 avg=0.18\n",
            "[888 | 676.42] loss=0.10 avg=0.18\n",
            "[889 | 678.72] loss=0.12 avg=0.18\n",
            "[890 | 681.03] loss=0.11 avg=0.18\n",
            "[891 | 683.33] loss=0.11 avg=0.18\n",
            "[892 | 685.64] loss=0.13 avg=0.17\n",
            "[893 | 687.94] loss=0.09 avg=0.17\n",
            "[894 | 690.24] loss=0.12 avg=0.17\n",
            "[895 | 692.54] loss=0.14 avg=0.17\n",
            "[896 | 694.85] loss=0.13 avg=0.17\n",
            "[897 | 697.16] loss=0.12 avg=0.17\n",
            "[898 | 699.47] loss=0.11 avg=0.17\n",
            "[899 | 701.77] loss=0.12 avg=0.17\n",
            "[900 | 704.09] loss=0.14 avg=0.17\n",
            "======== SAMPLE 1 ========\n",
            " and God in truth:\\\n",
            "For it is written, I will destroy them that dwell on the earth; and if the church be established in God's sight, then shall it also be spread abroad.\\\n",
            "And herein is that doctrine, that no man is new: for God is in every man.\\\n",
            "But what I now preach, teach, and exhort, that I go my way to the Lord, and he that sent me to her should she believe.\\\n",
            "For I determined before\n",
            "\n",
            "[901 | 707.34] loss=0.13 avg=0.17\n",
            "[902 | 709.65] loss=0.16 avg=0.17\n",
            "[903 | 711.95] loss=0.08 avg=0.17\n",
            "[904 | 714.25] loss=0.16 avg=0.17\n",
            "[905 | 716.55] loss=0.09 avg=0.17\n",
            "[906 | 718.86] loss=0.15 avg=0.17\n",
            "[907 | 721.16] loss=0.12 avg=0.17\n",
            "[908 | 723.47] loss=0.10 avg=0.17\n",
            "[909 | 725.77] loss=0.12 avg=0.17\n",
            "[910 | 728.08] loss=0.13 avg=0.17\n",
            "[911 | 730.38] loss=0.11 avg=0.17\n",
            "[912 | 732.69] loss=0.13 avg=0.17\n",
            "[913 | 735.00] loss=0.16 avg=0.16\n",
            "[914 | 737.30] loss=0.09 avg=0.16\n",
            "[915 | 739.60] loss=0.12 avg=0.16\n",
            "[916 | 741.91] loss=0.11 avg=0.16\n",
            "[917 | 744.22] loss=0.10 avg=0.16\n",
            "[918 | 746.51] loss=0.13 avg=0.16\n",
            "[919 | 748.82] loss=0.09 avg=0.16\n",
            "[920 | 751.12] loss=0.12 avg=0.16\n",
            "[921 | 753.43] loss=0.12 avg=0.16\n",
            "[922 | 755.73] loss=0.13 avg=0.16\n",
            "[923 | 758.04] loss=0.10 avg=0.16\n",
            "[924 | 760.34] loss=0.11 avg=0.16\n",
            "[925 | 762.65] loss=0.15 avg=0.16\n",
            "[926 | 764.95] loss=0.15 avg=0.16\n",
            "[927 | 767.25] loss=0.14 avg=0.16\n",
            "[928 | 769.55] loss=0.08 avg=0.16\n",
            "[929 | 771.87] loss=0.15 avg=0.16\n",
            "[930 | 774.17] loss=0.08 avg=0.16\n",
            "[931 | 776.48] loss=0.11 avg=0.16\n",
            "[932 | 778.78] loss=0.11 avg=0.16\n",
            "[933 | 781.08] loss=0.12 avg=0.16\n",
            "[934 | 783.39] loss=0.11 avg=0.16\n",
            "[935 | 785.69] loss=0.15 avg=0.16\n",
            "[936 | 788.00] loss=0.14 avg=0.16\n",
            "[937 | 790.31] loss=0.13 avg=0.15\n",
            "[938 | 792.61] loss=0.10 avg=0.15\n",
            "[939 | 794.92] loss=0.12 avg=0.15\n",
            "[940 | 797.23] loss=0.11 avg=0.15\n",
            "[941 | 799.53] loss=0.10 avg=0.15\n",
            "[942 | 801.84] loss=0.10 avg=0.15\n",
            "[943 | 804.14] loss=0.10 avg=0.15\n",
            "[944 | 806.46] loss=0.12 avg=0.15\n",
            "[945 | 808.76] loss=0.12 avg=0.15\n",
            "[946 | 811.06] loss=0.08 avg=0.15\n",
            "[947 | 813.37] loss=0.11 avg=0.15\n",
            "[948 | 815.67] loss=0.11 avg=0.15\n",
            "[949 | 817.97] loss=0.12 avg=0.15\n",
            "[950 | 820.28] loss=0.09 avg=0.15\n",
            "[951 | 822.58] loss=0.10 avg=0.15\n",
            "[952 | 824.88] loss=0.16 avg=0.15\n",
            "[953 | 827.18] loss=0.11 avg=0.15\n",
            "[954 | 829.48] loss=0.11 avg=0.15\n",
            "[955 | 831.78] loss=0.09 avg=0.15\n",
            "[956 | 834.08] loss=0.09 avg=0.15\n",
            "[957 | 836.38] loss=0.10 avg=0.15\n",
            "[958 | 838.69] loss=0.09 avg=0.15\n",
            "[959 | 840.99] loss=0.10 avg=0.15\n",
            "[960 | 843.28] loss=0.11 avg=0.14\n",
            "[961 | 845.59] loss=0.09 avg=0.14\n",
            "[962 | 847.89] loss=0.10 avg=0.14\n",
            "[963 | 850.20] loss=0.12 avg=0.14\n",
            "[964 | 852.50] loss=0.09 avg=0.14\n",
            "[965 | 854.81] loss=0.11 avg=0.14\n",
            "[966 | 857.11] loss=0.10 avg=0.14\n",
            "[967 | 859.43] loss=0.21 avg=0.14\n",
            "[968 | 861.74] loss=0.09 avg=0.14\n",
            "[969 | 864.04] loss=0.13 avg=0.14\n",
            "[970 | 866.34] loss=0.12 avg=0.14\n",
            "[971 | 868.65] loss=0.10 avg=0.14\n",
            "[972 | 870.95] loss=0.11 avg=0.14\n",
            "[973 | 873.25] loss=0.12 avg=0.14\n",
            "[974 | 875.56] loss=0.15 avg=0.14\n",
            "[975 | 877.88] loss=0.10 avg=0.14\n",
            "[976 | 880.18] loss=0.11 avg=0.14\n",
            "[977 | 882.48] loss=0.14 avg=0.14\n",
            "[978 | 884.78] loss=0.13 avg=0.14\n",
            "[979 | 887.08] loss=0.11 avg=0.14\n",
            "[980 | 889.39] loss=0.10 avg=0.14\n",
            "[981 | 891.68] loss=0.11 avg=0.14\n",
            "[982 | 893.98] loss=0.13 avg=0.14\n",
            "[983 | 896.28] loss=0.10 avg=0.14\n",
            "[984 | 898.58] loss=0.10 avg=0.14\n",
            "[985 | 900.89] loss=0.10 avg=0.14\n",
            "[986 | 903.20] loss=0.09 avg=0.14\n",
            "[987 | 905.49] loss=0.09 avg=0.14\n",
            "[988 | 907.79] loss=0.07 avg=0.14\n",
            "[989 | 910.09] loss=0.09 avg=0.14\n",
            "[990 | 912.39] loss=0.09 avg=0.14\n",
            "[991 | 914.70] loss=0.11 avg=0.14\n",
            "[992 | 917.00] loss=0.10 avg=0.13\n",
            "[993 | 919.31] loss=0.11 avg=0.13\n",
            "[994 | 921.60] loss=0.10 avg=0.13\n",
            "[995 | 923.90] loss=0.11 avg=0.13\n",
            "[996 | 926.21] loss=0.14 avg=0.13\n",
            "[997 | 928.52] loss=0.11 avg=0.13\n",
            "[998 | 930.83] loss=0.11 avg=0.13\n",
            "[999 | 933.14] loss=0.12 avg=0.13\n",
            "[1000 | 935.43] loss=0.34 avg=0.14\n",
            "Saving checkpoint/run1/model-1000\n",
            "======== SAMPLE 1 ========\n",
            " against the woman.\\\n",
            "Then when he had put his hands upon her neck, he clothed her likewise in a garment of soft washcloth:\\\n",
            "And said unto her, Your Grace, are these likewise? And Grace giveth us a place to rest.\\\n",
            "And Judas also, when he had put his hands again on her neck, returned from the wilderness,\\\n",
            "And prayed with an holy voice for his disciples, and cried them to be baptized for him.\\\n",
            "And when he\n",
            "\n",
            "[1001 | 941.71] loss=0.09 avg=0.14\n",
            "[1002 | 943.99] loss=0.10 avg=0.13\n",
            "[1003 | 946.28] loss=0.10 avg=0.13\n",
            "[1004 | 948.57] loss=0.10 avg=0.13\n",
            "[1005 | 950.87] loss=0.12 avg=0.13\n",
            "[1006 | 953.19] loss=0.07 avg=0.13\n",
            "[1007 | 955.50] loss=0.10 avg=0.13\n",
            "[1008 | 957.82] loss=0.08 avg=0.13\n",
            "[1009 | 960.14] loss=0.10 avg=0.13\n",
            "[1010 | 962.46] loss=0.08 avg=0.13\n",
            "[1011 | 964.79] loss=0.08 avg=0.13\n",
            "[1012 | 967.10] loss=0.13 avg=0.13\n",
            "[1013 | 969.43] loss=0.12 avg=0.13\n",
            "[1014 | 971.74] loss=0.12 avg=0.13\n",
            "[1015 | 974.05] loss=0.09 avg=0.13\n",
            "[1016 | 976.37] loss=0.09 avg=0.13\n",
            "[1017 | 978.68] loss=0.09 avg=0.13\n",
            "[1018 | 980.99] loss=0.10 avg=0.13\n",
            "[1019 | 983.29] loss=0.10 avg=0.13\n",
            "[1020 | 985.59] loss=0.09 avg=0.13\n",
            "[1021 | 987.90] loss=0.09 avg=0.13\n",
            "[1022 | 990.21] loss=0.13 avg=0.13\n",
            "[1023 | 992.50] loss=0.08 avg=0.13\n",
            "[1024 | 994.79] loss=0.09 avg=0.13\n",
            "[1025 | 997.08] loss=0.07 avg=0.13\n",
            "[1026 | 999.37] loss=0.07 avg=0.13\n",
            "[1027 | 1001.66] loss=0.12 avg=0.13\n",
            "[1028 | 1003.95] loss=0.11 avg=0.13\n",
            "[1029 | 1006.23] loss=0.10 avg=0.13\n",
            "interrupted\n",
            "Saving checkpoint/run1/model-1029\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fe09e5752fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m               steps=1000)   # max number of training steps\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'run1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(sess, run_name, checkpoint_dir, model_name, model_dir, sample_dir, return_as_list, truncate, destination_path, sample_delim, prefix, seed, nsamples, batch_size, length, temperature, top_k, top_p, include_prefix)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m     )[:, 1:]\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py\u001b[0m in \u001b[0;36msample_sequence\u001b[0;34m(hparams, length, start_token, batch_size, context, temperature, top_k, top_p)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# TODO: Would be slightly faster if we called step on the entire context,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# rather than leaving the last token transformer calculation to the while loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mcontext_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(hparams, tokens, past)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         lm_output = model.model(hparams=hparams, X=tokens,\n\u001b[0;32m---> 52\u001b[0;31m                                 past=past, reuse=tf.compat.v1.AUTO_REUSE)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(hparams, X, past, scope, gpus, reuse)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpasts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgpu_stack\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mpresents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\u001b[0m in \u001b[0;36mblock\u001b[0;34m(x, scope, past, hparams)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ln_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ln_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mlp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, scope, axis, epsilon)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m           y = ops.convert_to_tensor_v2(\n\u001b[0;32m--> 903\u001b[0;31m               y, dtype_hint=x.dtype.base_dtype, name=\"y\")\n\u001b[0m\u001b[1;32m    904\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1283\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         ret = conversion_func(\n\u001b[0;32m-> 1285\u001b[0;31m             value, dtype=preferred_dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[1;32m   1286\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;31m# Could not coerce the conversion to use the preferred dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    263\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    264\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    266\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m   const_tensor = g.create_op(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6AnyAtNmQUL",
        "outputId": "1acab10a-32bc-4b28-bad9-d5c1cbcc69e9"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1', prefix='lose your life', include_prefix=True, length=100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lose your life in the word of truth, and the Spirit of truth shall save your life unto eternal life.\\\n",
            "Be not deceived; God is not mocked: for whatsoever a man soweth, that shall he receive full harvest; but he shall be tormented with tribulation; from which also he shall receive part, because he soweth not.\\\n",
            "While he saith these things, we know that he spake unto us of the kingdom of God.\\\n",
            "For John to whom Jesus had given\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_kcuFCTt_pR",
        "outputId": "9e5640e1-c157-43c0-aa35-3dd9ded3888e"
      },
      "source": [
        "#@title Generate Your Own New Testament Verses\n",
        "prompt = '' #@param {type:\"string\"}\n",
        "\n",
        "print(gpt2.generate(sess, run_name='run1', prefix=prompt, include_prefix=False, length=50))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It was in the day when he was sent.\\\n",
            "And the Pharisees and lawyers stood there, expecting to find a recompence of goods.\\\n",
            "But the Son of man went in unto them, and sat down, and inched\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}